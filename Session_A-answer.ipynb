{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Session A 用到的套件，如果有 import error，請打開 Anaconda Prompt 並參考 https://github.com/afunTW/dsc-crawling 的教學安裝套件\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SESSION A: 爬蟲基本介紹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 簡單的 Python 教學 (本課程會用到的部分，有 Python 基礎的同學可以跳過) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python 的資料形態，本課程會用到的主要有兩種 \n",
    "1. List (串列)，把資料一個一個存在中括號 [ ] 裡面 \n",
    "2. Dictionary (字典)，把資料透過 key:value 的方式存在一個大括號 {} 裡面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "example_list = [1, 2, 3]\n",
    "print(type(example_list))\n",
    "print(example_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'a': 1, 'b': 2, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "example_dictionay = {\"a\":1, \"b\":2, \"c\":3}\n",
    "print(type(example_dictionay))\n",
    "print(example_dictionay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python 的 loop 寫法\n",
    "\n",
    "進到 list (串列)裡面，依序把裡面的值取出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "example_list = [1, 2, 3]\n",
    "for num in example_list:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一種簡潔的 loop 寫法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[num for num in example_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建立新 list\n",
    "\n",
    "進到 list (串列)裡面，依序把值取出來並+1，再放回 list 裡面，最後將這個 list 存成一個新的 new_example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "example_list = [1, 2, 3]\n",
    "print([num + 1 for num in example_list])\n",
    "new_example_list = [num + 1 for num in example_list] #　把加過 1 的新 list 存成新的 new_example_list 變數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 範例 00:  第一支爬蟲程式\n",
    "如何透過程式，取出[範例網頁](https://jimmy15923.github.io/example_page)中的大標題「Python 爬蟲實戰」?\n",
    "\n",
    "請打開[範例網頁: https://jimmy15923.github.io/example_page](https://jimmy15923.github.io/example_page)，並在「Python 爬蟲實戰」的文字上按右鍵 → 檢查，可以看到這段文字被包在 h1 的標籤中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Python 爬蟲實戰</h1>\n"
     ]
    }
   ],
   "source": [
    "# import 套件\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# 用 requests 抓取網頁 https://jimmy15923.github.io/example_page 並存在 response\n",
    "response =requests.get(\"https://jimmy15923.github.io/example_page\")\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "# 用 BS4 解析 HTML 並把結果回傳 soup (lxml 是 BeautifulSoup 的解析器，預設是使用 html.parser，但是 lxml 的速度及性能較佳)\n",
    "\n",
    "\n",
    "# 印出 h1 標籤\n",
    "print(soup.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requests 的函數\n",
    "requests 後的結果我們已經存成 response 這個變數，可以用許多 requests 內建的函數來了解 requets 回傳的結果 (可以輸入 response. 再按 tab 來看有甚麼函數)\n",
    "* [requests 官方文檔](http://docs.python-requests.org/en/master/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 確認 requests 的結果\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "# 確認目標網站的編碼 (requets 會自動猜測目標網站的編碼，若猜測錯誤會顯示亂碼，需要手動修改)\n",
    "print(response.encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n\\n<html>\\n<head>\\n\\t<meta charset=\"UTF-8\" />\\n\\t<title>網頁名稱-python crawler</title>\\n\\t<style>\\n\\t.abc {\\n\\t\\tcolor: blue;\\n\\t\\tfont-size: 40px;\\t\\n\\t}\\n\\n\\t#i-am-id {\\n\\t\\tbackground-color: LightCyan;\\n\\t}\\n\\n\\ttable, th, td {\\n\\t\\tborder: 1px solid black;\\n\\t    border-collapse: collapse;\\n\\t}\\n\\tth, td {\\n\\t\\tpadding: 10px;\\n\\t}\\n\\t</style>\\n</head>\\n<body>\\n\\t<h1>Python 爬蟲實戰</h1>\\n\\t<h2>這是 h2 標籤的內容</h2>\\n\\t<h3>這是 h3 標籤的內容</h3>\\n\\n\\t<p title=\"i-am-title\">這是 p 標籤的內容</p>\\n\\n\\t<div> \\n\\t這是 div 標籤的內容，\\n\\t即使換行寫，網頁顯示出的文字一樣是不會換行\\n\\t</div>\\n\\n\\t<p>但如果用了 br 標籤 <br/> 就可以順利斷行了</p>\\n\\t\\n\\t<div class = \"zzz\" id = \"id1\">我是有著屬性 class=\"zzz\" 的標籤內容</div>\\n\\t<p hidden>python_crawler</p>\\n\\t<div id = \"value-of-attr\">\\n\\t我是有著屬性 id=\"value-of-attr\" 的標籤內容\\n\\t\\n\\t\\t<table id = \"i-am-id\">\\n\\t\\t  <tr>\\n\\t\\t\\t<th>標頭 1 (table-header)</th>\\n\\t\\t\\t<th>標頭 2 (table-header)</th>\\n\\t\\t\\t<th>標頭 3 (table-header)</th>\\n\\t\\t\\t<th>標頭 4 (table-header)</th>\\n\\t\\t  </tr>\\n\\t\\t  <tr>\\n\\t\\t\\t<td> 列2 欄1 </td>\\n\\t\\t\\t<td class = \"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>\\n\\t\\t\\t<td> \\n\\t\\t\\t\\t<a href = \"http://www.yahoo.com.tw\">列2 欄3 (我是 a 標籤，屬性 href=網址) </a> \\n\\t\\t\\t</td>\\n\\t\\t\\t<td> \\n\\t\\t\\t\\t<a href = \"http://foundation.datasci.tw/\">列2 欄4 (資料協會) </a>  \\n\\t\\t\\t</td>\\n\\t\\t  </tr>\\n\\t\\t  <tr>\\n\\t\\t\\t<td value = \"5566\">列3 欄1 </td>\\n\\t\\t\\t<td>列3 欄2\\n\\t\\t\\t\\t<ol>\\n\\t\\t\\t\\t\\t<li class = \"zz\">我是 li 標籤 (列表)，屬性 class=\"zz\" </li>\\n\\t\\t\\t\\t\\t<li> 第二個 li 標籤 </li>\\n\\t\\t\\t\\t</ol>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td>\\n\\t\\t\\t\\t<a href = \"http://foundation.datasci.tw/python-crawling-170813/\" id = \"hyperlink\"> 列3 欄3 (資料協會-python 爬蟲實戰)</a>\\n\\t\\t\\t</td>\\n\\t\\t\\t<td class = \"zzzz\">列3 欄4 (我的屬性 class=\"zzzz\")</td>\\n\\t\\t  </tr>\\n\\n\\t\\t</table>\\n\\t</div>\\n\\n\\t<p>python_crawler</p>\\n\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 目標網站的 HTML\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 練習 00: 淺嘗 BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# please insert the codes from slides, you can press shift + enter or ctrl + enter to run this cell\n",
    "# your codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 範例 01: BeautifulSoup 的常用函數\n",
    "將 HTML 抓下來後，其本身就是一個很大的字串，也當然可以用 regular expression 找出想要的資訊，But to make your life easier，我們可以使用 BeautifulSoup 這個 HTML parser，幫助解析 HTML，並使用許多便捷的 function，讓我們能夠更簡單的找到目標資訊\n",
    "\n",
    "小故事: 關於 BeautifulSoup 的名稱，是來自《愛麗絲夢遊仙境》裡一首詩的名稱，是由下圖中的左邊那隻假的海龜 (The Mock Turtle) 所唱出來的\n",
    "![BS4](data/bs4.jpg)\n",
    "補充資料\n",
    "\n",
    "* 更多 BeautifulSoup 的 funcion 請參考[官方文檔 (有中文版)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    "以下的範例會示範兩個常用的函數: find(), find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"https://jimmy15923.github.io/example_page\")\n",
    "soup = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td> 列2 欄1 </td>\n",
      "\n",
      "\n",
      " 列2 欄1 \n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"td\"))  # 找出第一個名為 td 的標籤\n",
    "print(\"\\n\") # 換行符號，讓兩個 Print 的結果中間可以隔一個空行\n",
    "print(soup.find(\"td\").text)     # 找出第一個名為 td 的標籤並印出其文字內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "\n",
      "\n",
      "[<td> 列2 欄1 </td>, <td class=\"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>, <td>\n",
      "<a href=\"http://www.yahoo.com.tw\">列2 欄3 (我是 a 標籤，屬性 href=網址) </a>\n",
      "</td>, <td>\n",
      "<a href=\"http://foundation.datasci.tw/\">列2 欄4 (資料協會) </a>\n",
      "</td>, <td value=\"5566\">列3 欄1 </td>, <td>列3 欄2\n",
      "\t\t\t\t<ol>\n",
      "<li class=\"zz\">我是 li 標籤 (列表)，屬性 class=\"zz\" </li>\n",
      "<li> 第二個 li 標籤 </li>\n",
      "</ol>\n",
      "</td>, <td>\n",
      "<a href=\"http://foundation.datasci.tw/python-crawling-170813/\" id=\"hyperlink\"> 列3 欄3 (資料協會-python 爬蟲實戰)</a>\n",
      "</td>, <td class=\"zzzz\">列3 欄4 (我的屬性 class=\"zzzz\")</td>]\n"
     ]
    }
   ],
   "source": [
    "print(type(soup.find_all(\"td\"))) # find_all 回傳的是 list\n",
    "print(\"\\n\")\n",
    "print(soup.find_all(\"td\")) # 找出所有 td 的標籤，並回傳 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"zzz\" id=\"id1\">我是有著屬性 class=\"zzz\" 的標籤內容</div>, <td class=\"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>]\n",
      "\n",
      "\n",
      "[<div class=\"zzz\" id=\"id1\">我是有著屬性 class=\"zzz\" 的標籤內容</div>, <td class=\"zzz\"> 列2 欄2 (我的屬性 class=\"zzz\") </td>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(\"\", {\"class\":\"zzz\"}))     # 不指定標籤，但找出所有屬性 class = \"zzz\" 的標籤\n",
    "print(\"\\n\")\n",
    "print(soup.find_all(\"\", class_=\"zzz\"))     # 不同寫法 但有一樣的結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td>\n",
      "<a href=\"http://www.yahoo.com.tw\">列2 欄3 (我是 a 標籤，屬性 href=網址) </a>\n",
      "</td>\n",
      "\n",
      "\n",
      "<a href=\"http://www.yahoo.com.tw\">列2 欄3 (我是 a 標籤，屬性 href=網址) </a>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(\"td\")[2])  # 找到所有 td 的標籤，然後在第三個 (python index 從 0 開始) td 標籤中，再找出 a 標籤\n",
    "print(\"\\n\")\n",
    "print(soup.find_all(\"td\")[2].find(\"a\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python_crawler', 'python_crawler']\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(text = \"python_crawler\"))   # 找出所有標籤文字內容等於 python_crawler 的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'http://www.yahoo.com.tw'}\n",
      "http://www.yahoo.com.tw\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"a\").attrs)     # 以 Dictionary (字典) 的形式儲存標籤的屬性\n",
    "print(soup.find(\"a\")['href'])     # 找出標籤屬性中的超連結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 爬蟲實戰\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"h1\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習 01: 基本的 BeautifulSoup 使用 (8 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請觀察[範例網頁](https://jimmy15923.github.io/example_page)後，嘗試回答以下的問題\n",
    "\n",
    "\n",
    "    \n",
    "    jupyter notebook 的幾個實用 hotkey\n",
    "    * alt+enter: 執行 cell 並往下新增一個 cell\n",
    "    * shift+enter: 執行 cell 並往下一個 cell (不新增)\n",
    "    * esc+a: 往上新增一個 cell\n",
    "    * esc+b: 往下新增一個 cell\n",
    "    * esc+d+d (d 按兩次): 刪除 cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例網頁: \"https://jimmy15923.github.io/example_page\"\n",
    "# 1. 發送 requests.get，並將結果存在 response (或自己定義喜歡的變數也可以)\n",
    "# your codes\n",
    "response = requests.get(\"https://jimmy15923.github.io/example_page\")\n",
    "\n",
    "# 2. 將 response 的 HTML 文字放進 BeautifulSoup，並將結果存在 soup (或自己定義喜歡的變數也可以)\n",
    "# your codes\n",
    "soup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. 請計算範例網頁中，共含有幾個名為 \"td\" 的標籤 (tags)?\n",
    "\n",
    "Hint: Python 的 len() 函數可以幫忙計算 list 的長度。\n",
    "e.g. len([1,1,1]) 會回傳 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# your codes\n",
    "print(len(soup.find_all(\"td\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. 請找出**標籤 div，屬性 id = \"id1\"** 的文字內容?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是有著屬性 class=\"zzz\" 的標籤內容\n"
     ]
    }
   ],
   "source": [
    "# your codes\n",
    "print(soup.find(\"div\", id = \"id1\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. 請找出**列3欄3**背後的超連結網址? (請使用 BeautifulSoup + 右鍵→檢查 來找到那個標籤，不要偷偷從網頁點開連結來看喔^^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://foundation.datasci.tw/python-crawling-170813/\n"
     ]
    }
   ],
   "source": [
    "# your codes\n",
    "print(soup.find(\"a\",id=\"hyperlink\")[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 範例 02: regular expression\n",
    "regular expression 是在搜尋大量文字時非常好用的工具，可以快速回傳符合您要求的文字\n",
    "\n",
    "例如尋找任何像是電話號碼、E-mail 信箱的文字\n",
    "\n",
    "範例 02 會透過一些簡單的練習帶您了解 regular expression\n",
    "\n",
    "\n",
    "\n",
    "補充資料\n",
    "\n",
    "* [更詳盡的 regular expression 符號解釋](https://atedev.wordpress.com/2007/11/23/%E6%AD%A3%E8%A6%8F%E8%A1%A8%E7%A4%BA%E5%BC%8F-regular-expression/)\n",
    "* [regular expression 線上練習網站](https://regexone.com/)\n",
    "* [常見的 regular expression 寫法](https://www.analyticsvidhya.com/blog/2017/03/extracting-information-from-reports-using-regular-expressons-library-in-python/)\n",
    "* 如果想擷取中文的 regular expression，可用[\\u4e00-\\u9fa5]，會幫你找出所有中文字，其結果如同英文的 [A-Z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regular expression 的符號意義\n",
    "![BS4](data/reg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下的練習您可以使用 python 內建的 re 套件，也可以使用這個[線上regular expression 測試器](https://regex101.com/)，可以看到比較互動式的結果，使用方法只要把 test_string 裡的內容複製到網頁下方的 TEST STRING 空格，然後在網頁上方的空格輸入您的  regular expression，就可以看到匹配的結果，左邊的 FLAVOR 記得選擇 python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例 02-1:  *, +, {} 的用法\n",
    "\\* 代表前面的字元可出現零次以上，而 + 則是代表前面的字元至少要出現一次以上，{m,n} 則是代表前面的字元可出現 m 次 ~ n 次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aabc', 'ac']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"a+b*c\"\n",
    "test_string = 'find aabc, ac, skip abb, dd'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 02-1: *, +, {} 的用法\n",
    "在 test_string 中找出 abbbbc, bc，但不包含 c, acc\n",
    "\n",
    "Hint: 思考一下要尋找的文字跟要濾除的文字，在字母之間有甚麼差異，先把 find 寫出來，再想辦法去掉要 skip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbbbc', 'bc']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### your codes\n",
    "pattern = \"a*b+c\"\n",
    "test_string = 'find abbbbc, bc, skip c, acc'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例 02-2: 找到英數字\n",
    "中括號代表的意思是「這個字元可以是括號內的任何一個」，以數字為例，[0-9]代表這個字元可以是 0~9 之間的任意數字，如果是 [a-z] 則代表是小寫字母 a~z 之間的任意文字，聰明的你，應該可以猜出 [A-Z] 代表的是甚麼意思吧?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '11', '10']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"[0-9]+\"\n",
    "test_string = '12 drummers drumming, 11 pipers piping, 10 lords a-leaping'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### 練習 02-2: 找到英數字\n",
    "在 test_string 中找出所有數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123', '123', '123', '123']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your codes\n",
    "pattern = \"[1-3]+\"\n",
    "test_string = 'abc123xyz, de123fine\"123\", test = 123'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例 02-3: 找到文字\n",
    "當有指定的文字需要搜尋，可透過 [ ] 搭配 *, + ,{} 進行搜尋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can', 'man', 'fan']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"[cmf]an\"\n",
    "test_string = 'find: can, man, fan, skip: dan, ran, pan'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jimmy', 'jimmmy', 'jimmmmmy']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"jim{2,5}y\"\n",
    "test_string = 'find: jimmy, jimmmy, jimmmmmy, skip: jimy'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 02-3: 找到文字\n",
    "在 test_string 中找出 ABi, BBc, CNn，但不包含 ai, be, cd\n",
    "\n",
    "Hint: 如果只找到一個大寫字母，想想甚麼符號代表可出現一次以上?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABi', 'BBc', 'CNn']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your codes\n",
    "pattern = \"[A-Z]+[a-z]\"\n",
    "test_string = 'find: ABi, BBc, CNn, skip: ai, be, cd'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例 02-4: 跳脫符號\n",
    "當想要搜尋的字元，在 regular expression 已經是保留字的時候，就要使用跳脫符號\n",
    "\n",
    "例如你想要搜尋符合 \"+\" (加號) 這個文字，但是 \"+\" 在 regular expression 是代表出現一次以上的意思\n",
    "\n",
    "這時在 \"+\" 前面加上 \"\\\" (跳脫符號)，這樣做的話 regular expression 就會知道你是要尋找 \"+\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['591.', 'dot.', 'yes.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \".{3}\\.\"\n",
    "test_string = 'find: 591., dot., yes., skip: non!'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 02-4: 跳脫符號\n",
    "在 test_string 中找到 A+c, B+d, C+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A+c', 'B+d', 'C+x']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your codes\n",
    "pattern = \"[A-Z]\\+[a-z]\"\n",
    "test_string = 'find: A+c, B+d, C+x'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例 02-5: 條件式搜尋\n",
    "當希望不同的搜尋條件都能夠符合時，可以使用「|」這個符號，代表左右邊只要任一一個條件符合，就會回傳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love cats', 'I love dogs']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"I love cats|I love dogs\"\n",
    "test_string = 'find: I love cats, I love dogs, skip: I love logs, I love cogs'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 02-5: 條件式搜尋\n",
    "在 test_string 中找到 jimy, jimmmy, 但不包含 jimmy, jimmmmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jimy', 'jimmmy']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your codes\n",
    "pattern = \"jimy|jim{3}y\"\n",
    "test_string = 'find: jimy, jimmmy, skip: jimmy, jimmmmy'\n",
    "re.findall(pattern, test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  範例 02-6: Email 搜尋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_text = \"\"\"\n",
    "Big Data Analytics/ Deep LearningSocial Computing / Computational Social Science / Crowdsourcing\n",
    "Multimediaand Network SystemsQuality of ExperienceInformation SecurityPh.D. candidate at NTU EEchihfan02-27883799#1602Camera CalibrationComputer VisionData\n",
    "Analysiscmchang02-27883799#1671System OptimizationMachine LearningyusraBig data\n",
    "analysiscclin02-27883799#1668Data Analysisrusi02-27883799#1668Government Procurement ActFinancial\n",
    "Managementkatekuen02-27883799#1602AdministrationEvent Planningseanyu02-27883799#1668Data \n",
    "AnalysisPsychology & NeuroscienceMarketingxinchinchenEmbedded Systemkyoyachuan062602-27883799\n",
    "#1601FinTechActuarial ScienceData Analysiskai0604602-27883799#1601Data AnalysisMachine Learningchloe02-27839427Accountingafun02-27883799 afun@iis.sinica.edu.tw\n",
    "#1673Data AnalysisWeb developmentyunhsu198902-27883799#1668MarketingTIGP Ph.D. Fellow at Academia Sinica & NCCUbaowalyMachine LearningData AnalysisSocial Computingchangyc1427883799#1678\n",
    "Data Analysisjimmy1592302-2788379 jimmy15923@iis.sinica.com.tw#1688Data AnalysisjasontangAnalysisMachine Learninguchen02-27883799#1668Deep Learningpjwu02-27883799#1604Computational PhotographyData Analysis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('afun@iis.sinica.edu.tw', 'edu'), ('jimmy15923@iis.sinica.com.tw', 'com')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"([A-Za-z0-9._]+@[A-Za-z.]+(com|edu)\\.tw)\", email_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習 02: regular expression (8 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請觀察[518 黃頁網](http://yp.518.com.tw/service-life.html?ctf=10)，並找出所有店家的電話號碼 (包含分機)\n",
    "\n",
    "Hint\n",
    "* 想要的資訊都藏在哪些標籤下?\n",
    "* 把所有可能包含電話的標籤內容全部找出來後，用下面的 code 變成一個字串\n",
    "* text = \" \".join(text_list)，這段 code 可以將 list of string 全部變為一個字串\n",
    "* 變成字串後就可以用剛剛學的 re.findall() 找出我們要的目標囉!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 如果忘記怎麼寫 requests 或 BeautifulSoup，可以參考\n",
    "\n",
    "# response = requests.get(\"http://yp.518.com.tw/service-life.html?ctf=10\")\n",
    "# print(response.encoding)\n",
    "\n",
    "# soup = BeautifulSoup(response.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8\n",
      "['02-29242789', '03-4709933', '04-23601719', '06-2092929', '05-2238686', '07-6994433', '07-3610768', '02-29662939', '02-29662939', '02-29609370']\n"
     ]
    }
   ],
   "source": [
    "# your codes\n",
    "\n",
    "response = requests.get(\"http://yp.518.com.tw/service-life.html?ctf=10\")\n",
    "print(response.encoding)\n",
    "soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "all_phone_text = [tag.text for tag in soup.find_all(\"li\",class_=\"comp_tel\")]\n",
    "all_phone_text =\"\".join(all_phone_text)\n",
    "\n",
    "phone_number = re.findall(\"0[1-9]+-[0-9]+\", all_phone_text)\n",
    "print(phone_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
